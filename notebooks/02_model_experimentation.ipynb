{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463bd60",
   "metadata": {},
   "source": [
    "# PATH AND BASIC CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the root directory for data\n",
    "ROOT_DATA_DIR = Path(\"/Volumes/Data_Bravo/Google_research_open_contrail\")\n",
    "TRAIN_DATA_DIR = ROOT_DATA_DIR / \"train\"\n",
    "TEST_DATA_DIR = ROOT_DATA_DIR / \"validation\"\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "SEED = 19\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Setting MPS device to accelerate training\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"✅ MPS device available, using it for training.\")\n",
    "else:\n",
    "    print(\"❌ MPS device not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a6697",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 数据预处理和图像生成工具函数\n",
    "# ============================\n",
    "\n",
    "# 温度范围常量定义 - 用于卫星图像数据的归一化\n",
    "# 这些范围基于卫星图像中各波段的物理特性和经验值\n",
    "_T11_BOUNDS = (243, 303)  # Band 11 温度范围 (Kelvin)，用于蓝色通道\n",
    "_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)  # Band 14-11 温度差范围，用于绿色通道，帮助识别云顶特征\n",
    "_TDIFF_BOUNDS = (-4, 2)  # Band 15-14 温度差范围，用于红色通道，帮助区分不同类型的云和飞机尾迹\n",
    "\n",
    "def get_band_images(idx: str, parrent_folder: str, band: str) -> np.array:\n",
    "    \"\"\"\n",
    "    从指定路径加载卫星图像的单个波段数据\n",
    "    \n",
    "    Args:\n",
    "        idx (str): 样本ID，对应文件夹名称\n",
    "        parrent_folder (str): 父级文件夹名称 ('train' 或 'validation')\n",
    "        band (str): 波段编号 ('11', '14', '15' 等)\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 加载的波段数据，形状通常为 (height, width, time_frames)\n",
    "    \"\"\"\n",
    "    return np.load(\n",
    "        os.path.join(ROOT_DATA_DIR, parrent_folder, idx, f'band_{band}.npy')\n",
    "    )\n",
    "\n",
    "def normalize_range(data, bounds):\n",
    "    \"\"\"\n",
    "    将数据归一化到 [0, 1] 范围内\n",
    "    \n",
    "    为什么需要归一化：\n",
    "    1. 不同波段的数值范围差异很大，归一化后便于模型学习\n",
    "    2. 有助于梯度下降的稳定性和收敛速度\n",
    "    3. 防止某些特征因数值过大而主导模型学习过程\n",
    "    4. 使得RGB图像的每个通道都在合理的显示范围内\n",
    "    \n",
    "    Args:\n",
    "        data: 输入数据数组\n",
    "        bounds: 数据的 (最小值, 最大值) 元组\n",
    "    \n",
    "    Returns:\n",
    "        归一化后的数据，范围 [0, 1]\n",
    "    \n",
    "    注意：超出bounds范围的值会被映射到 <0 或 >1，通常配合 np.clip 使用\n",
    "    \"\"\"\n",
    "    return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "\n",
    "\n",
    "def get_ash_color_images(\n",
    "    idx: str, parrent_folder: str, get_mask_frame_only=False\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    生成假彩色合成图像用于飞机尾迹检测\n",
    "    \n",
    "    这个函数创建了一个专门用于检测飞机尾迹的RGB假彩色图像：\n",
    "    - 红色通道 (R): Band 15-14 温度差，突出显示不同高度的云层差异\n",
    "    - 绿色通道 (G): Band 14-11 温度差，帮助识别云顶温度特征\n",
    "    - 蓝色通道 (B): Band 14 绝对温度，提供基础温度信息\n",
    "    \n",
    "    为什么使用假彩色：\n",
    "    1. 人眼无法直接观察红外波段，假彩色将不可见信息转换为可见信息\n",
    "    2. 温度差异比绝对温度更能突出飞机尾迹的特征\n",
    "    3. 多波段组合能够增强目标与背景的对比度\n",
    "    \n",
    "    Args:\n",
    "        idx (str): 样本ID\n",
    "        parrent_folder (str): 数据文件夹 ('train' 或 'validation')\n",
    "        get_mask_frame_only (bool): 是否只获取mask对应的时间帧 (第4帧，索引为4)\n",
    "    \n",
    "    Returns:\n",
    "        np.array: RGB假彩色图像，形状为 (height, width, 3) 或 (height, width, time_frames, 3)\n",
    "                 数值范围 [0, 1]\n",
    "    \"\"\"\n",
    "    # 加载三个关键的红外波段\n",
    "    band11 = get_band_images(idx, parrent_folder, '11')  # 8.6 μm 波段\n",
    "    band14 = get_band_images(idx, parrent_folder, '14')  # 11.2 μm 波段  \n",
    "    band15 = get_band_images(idx, parrent_folder, '15')  # 12.4 μm 波段\n",
    "\n",
    "    # 如果只需要mask对应的时间帧，则提取第4帧\n",
    "    if get_mask_frame_only:\n",
    "        band11 = band11[:, :, 4]\n",
    "        band14 = band14[:, :, 4] \n",
    "        band15 = band15[:, :, 4]\n",
    "\n",
    "    # 计算假彩色通道\n",
    "    # 红色：Band 15-14 差值，用于检测冰晶云的特征\n",
    "    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n",
    "    # 绿色：Band 14-11 差值，用于检测云顶高度和温度特征\n",
    "    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "    # 蓝色：Band 14 绝对温度，提供基础热辐射信息\n",
    "    b = normalize_range(band14, _T11_BOUNDS)\n",
    "    \n",
    "    # 将三个通道合并为RGB图像，并限制在 [0,1] 范围内\n",
    "    false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n",
    "    return false_color\n",
    "\n",
    "def get_mask_image(idx: str, parrent_folder: str) -> np.array:\n",
    "    \"\"\"\n",
    "    加载人工标注的像素级掩码\n",
    "    \n",
    "    Args:\n",
    "        idx (str): 样本ID\n",
    "        parrent_folder (str): 数据文件夹\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 二值掩码，1表示飞机尾迹像素，0表示背景像素\n",
    "                 形状通常为 (height, width, time_frames)\n",
    "    \"\"\"\n",
    "    return np.load(\n",
    "        os.path.join(ROOT_DATA_DIR, parrent_folder, idx, 'human_pixel_masks.npy')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7dfa6",
   "metadata": {},
   "source": [
    "# MODEL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7550f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# ============================\n",
    "# U-Net 语义分割模型定义\n",
    "# ============================\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net中的双卷积块 - U-Net的基础构建单元\n",
    "    \n",
    "    结构：Conv2d -> BatchNorm2d -> ReLU -> Conv2d -> BatchNorm2d -> ReLU\n",
    "    \n",
    "    设计原理：\n",
    "    1. 双卷积增加网络深度，提高特征提取能力\n",
    "    2. BatchNorm加速训练收敛，提高模型稳定性\n",
    "    3. ReLU激活函数解决梯度消失问题，增加非线性\n",
    "    4. padding=1保持特征图尺寸不变\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): 输入通道数\n",
    "        out_channels (int): 输出通道数\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            # 第一个卷积层：提取局部特征\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),  # 批归一化：稳定训练，加速收敛\n",
    "            nn.ReLU(inplace=True),         # 非线性激活\n",
    "            \n",
    "            # 第二个卷积层：进一步细化特征\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net编码器的下采样块\n",
    "    \n",
    "    结构：MaxPool2d -> DoubleConv\n",
    "    \n",
    "    功能：\n",
    "    1. MaxPool2d：将特征图尺寸减半，扩大感受野\n",
    "    2. DoubleConv：提取更高级的语义特征\n",
    "    \n",
    "    在编码器路径中：\n",
    "    - 逐渐减小空间分辨率 (H, W)\n",
    "    - 逐渐增加特征通道数 (C)\n",
    "    - 捕获更大范围的上下文信息\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),  # 2x2最大池化，尺寸减半\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net解码器的上采样块\n",
    "    \n",
    "    功能：\n",
    "    1. 上采样：恢复空间分辨率\n",
    "    2. 跳跃连接：融合编码器的低级特征和解码器的高级特征\n",
    "    3. 双卷积：整合多尺度特征\n",
    "    \n",
    "    跳跃连接的重要性：\n",
    "    - 保留细节信息：编码器的浅层特征包含丰富的空间细节\n",
    "    - 梯度流通：帮助梯度更好地反向传播\n",
    "    - 多尺度融合：结合不同层次的特征表示\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            # 双线性插值上采样：计算效率高，参数少\n",
    "            self.up = nn.Upsample(\n",
    "                scale_factor=2, mode='bilinear', align_corners=True\n",
    "            )\n",
    "        else:\n",
    "            # 转置卷积上采样：可学习的上采样，但参数更多\n",
    "            self.up = nn.ConvTranspose2d(\n",
    "                in_channels // 2, in_channels // 2, kernel_size=2, stride=2\n",
    "            )\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x1: 来自上一层解码器的特征 (低分辨率，高语义)\n",
    "            x2: 来自编码器跳跃连接的特征 (高分辨率，低语义)\n",
    "        \"\"\"\n",
    "        # 上采样x1到与x2相同的空间尺寸\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        # 处理尺寸不匹配问题（由于池化可能导致的尺寸不完全匹配）\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        # 对x1进行padding以匹配x2的尺寸\n",
    "        x1 = nn.functional.pad(\n",
    "            x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2]\n",
    "        )\n",
    "\n",
    "        # 跳跃连接：在通道维度上连接两个特征图\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net语义分割网络\n",
    "    \n",
    "    网络架构：\n",
    "    1. 编码器路径 (收缩路径)：\n",
    "       - 逐层下采样，提取多尺度特征\n",
    "       - 通道数递增：3→64→128→256→512→512\n",
    "       - 空间尺寸递减：256×256→128×128→64×64→32×32→16×16→8×8\n",
    "    \n",
    "    2. 解码器路径 (扩张路径)：\n",
    "       - 逐层上采样，恢复空间分辨率\n",
    "       - 跳跃连接融合编码器特征\n",
    "       - 通道数递减：1024→512→256→128→64\n",
    "       - 空间尺寸递增：8×8→16×16→32×32→64×64→128×128→256×256\n",
    "    \n",
    "    3. 输出层：\n",
    "       - 1×1卷积将64通道特征映射到1通道\n",
    "       - 输出每个像素属于飞机尾迹的概率logits\n",
    "    \n",
    "    输入：(batch_size, 24, 256, 256) - 24通道假彩色图像序列\n",
    "    输出：(batch_size, 1, 256, 256) - 单通道分割掩码\n",
    "    \n",
    "    适用于飞机尾迹检测的原因：\n",
    "    1. 保持空间细节：跳跃连接保留了像素级精度\n",
    "    2. 多尺度特征：能够捕获不同尺度的尾迹形状\n",
    "    3. 上下文信息：编码器提供足够的感受野\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 编码器路径 (下采样)\n",
    "        self.inc = DoubleConv(24, 64)    # 初始卷积：24→64通道\n",
    "        self.down1 = Down(64, 128)       # 第1次下采样：64→128通道\n",
    "        self.down2 = Down(128, 256)      # 第2次下采样：128→256通道  \n",
    "        self.down3 = Down(256, 512)      # 第3次下采样：256→512通道\n",
    "        self.down4 = Down(512, 512)      # 第4次下采样：512→512通道 (瓶颈层)\n",
    "        \n",
    "        # 解码器路径 (上采样)\n",
    "        self.up1 = Up(1024, 256)         # 第1次上采样：1024→256通道 (512+512跳跃连接)\n",
    "        self.up2 = Up(512, 128)          # 第2次上采样：512→128通道 (256+256跳跃连接)\n",
    "        self.up3 = Up(256, 64)           # 第3次上采样：256→64通道 (128+128跳跃连接)\n",
    "        self.up4 = Up(128, 64)           # 第4次上采样：128→64通道 (64+64跳跃连接)\n",
    "        \n",
    "        # 输出层：将64通道特征映射为1通道分割结果\n",
    "        self.outc = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播过程\n",
    "        \n",
    "        Args:\n",
    "            x: 输入张量 (batch_size, 24, 256, 256)\n",
    "            \n",
    "        Returns:\n",
    "            输出张量 (batch_size, 1, 256, 256) - 分割logits\n",
    "        \"\"\"\n",
    "        # 编码器路径：逐层提取特征并保存跳跃连接\n",
    "        x1 = self.inc(x)      # [B, 64, 256, 256]\n",
    "        x2 = self.down1(x1)   # [B, 128, 128, 128]  \n",
    "        x3 = self.down2(x2)   # [B, 256, 64, 64]\n",
    "        x4 = self.down3(x3)   # [B, 512, 32, 32]\n",
    "        x5 = self.down4(x4)   # [B, 512, 16, 16]\n",
    "        \n",
    "        # 解码器路径：逐层上采样并融合跳跃连接\n",
    "        x = self.up1(x5, x4)  # [B, 256, 32, 32]\n",
    "        x = self.up2(x, x3)   # [B, 128, 64, 64]\n",
    "        x = self.up3(x, x2)   # [B, 64, 128, 128]  \n",
    "        x = self.up4(x, x1)   # [B, 64, 256, 256]\n",
    "        \n",
    "        # 输出层：生成最终的分割掩码\n",
    "        x = self.outc(x)      # [B, 1, 256, 256]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型并将其移动到MPS设备\n",
    "model = UNet()\n",
    "\n",
    "summary(model, input_size=(24, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c081e6b",
   "metadata": {},
   "source": [
    "# TRAINNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de46f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 损失函数定义\n",
    "# ============================\n",
    "\n",
    "class Dice(nn.Module):\n",
    "    \"\"\"\n",
    "    Dice系数（Sørensen-Dice系数）- 语义分割中的重要评估指标\n",
    "    \n",
    "    Dice系数公式：Dice = 2×|A∩B| / (|A| + |B|)\n",
    "    其中：\n",
    "    - A: 预测的正例像素集合\n",
    "    - B: 真实的正例像素集合  \n",
    "    - |A∩B|: 预测和真实都为正例的像素数量（真正例）\n",
    "    - |A|: 预测为正例的像素总数\n",
    "    - |B|: 真实正例的像素总数\n",
    "    \n",
    "    为什么使用Dice系数：\n",
    "    1. 类别不平衡处理：飞机尾迹像素通常只占图像的很小部分，Dice系数对正例更敏感\n",
    "    2. 重叠度量：直接衡量预测区域与真实区域的重叠程度，符合分割任务的评估需求\n",
    "    3. 可微分：可以作为损失函数进行反向传播训练\n",
    "    4. 范围 [0,1]：1表示完美重叠，0表示完全不重叠\n",
    "    \n",
    "    与其他指标的比较：\n",
    "    - 准确率 (Accuracy): 在极不平衡数据中容易被背景像素主导\n",
    "    - IoU (Intersection over Union): 与Dice相关，但Dice对小目标更友好\n",
    "    - 交叉熵损失: 逐像素计算，不考虑区域的连通性\n",
    "    \n",
    "    Args:\n",
    "        use_sigmoid (bool): 是否对输入应用sigmoid激活\n",
    "                           True: 输入为logits，需要转换为概率\n",
    "                           False: 输入已经是概率值\n",
    "    \"\"\"\n",
    "    def __init__(self, use_sigmoid=True):\n",
    "        super(Dice, self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \"\"\"\n",
    "        计算Dice系数\n",
    "        \n",
    "        Args:\n",
    "            inputs: 模型预测输出 (batch_size, 1, H, W)\n",
    "                   如果use_sigmoid=True，则为logits；否则为概率\n",
    "            targets: 真实标签 (batch_size, 1, H, W)，二值掩码，0或1\n",
    "            smooth: 平滑常数，防止分母为0，提高数值稳定性\n",
    "                   较小的smooth值使得Dice对小目标更敏感\n",
    "        \n",
    "        Returns:\n",
    "            dice: Dice系数，范围 [0, 1]\n",
    "        \n",
    "        计算细节：\n",
    "        1. 将多维张量展平为一维，便于计算交集和并集\n",
    "        2. 计算intersection：预测和真实都为正的像素数量\n",
    "        3. 应用Dice公式，加入平滑项避免除零错误\n",
    "        \"\"\"\n",
    "        # 如果输入是logits，转换为概率\n",
    "        if self.use_sigmoid:\n",
    "            inputs = self.sigmoid(inputs)\n",
    "\n",
    "        # 将张量展平为一维向量，便于计算像素级的交集\n",
    "        # 原始形状：(batch_size, 1, H, W) -> 展平后：(batch_size * H * W)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # 计算交集：预测为正且真实为正的像素数量\n",
    "        # inputs * targets: 逐元素相乘，只有都为1时结果才为1\n",
    "        intersection = (inputs * targets).sum()\n",
    "        \n",
    "        # 应用Dice公式\n",
    "        # 分子：2 * 交集 + 平滑项\n",
    "        # 分母：预测正例总数 + 真实正例总数 + 平滑项\n",
    "        dice = (2.0 * intersection + smooth) / (\n",
    "            inputs.sum() + targets.sum() + smooth\n",
    "        )\n",
    "\n",
    "        return dice\n",
    "\n",
    "\n",
    "# 实例化Dice评估器\n",
    "# 注意：这里创建的是评估指标，不是损失函数\n",
    "# 训练时通常使用 1 - Dice 作为损失函数，或使用专门的DiceLoss\n",
    "dice = Dice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.amp import autocast\n",
    "\n",
    "torch.set_autocast_enabled(True)\n",
    "\n",
    "# ============================\n",
    "# 模型训练器类\n",
    "# ============================\n",
    "\n",
    "\n",
    "class MyTrainer:\n",
    "    \"\"\"\n",
    "    自定义训练器类 - 封装深度学习模型的训练和验证流程\n",
    "\n",
    "    功能特性：\n",
    "    1. 训练循环管理：自动化epoch和batch的迭代\n",
    "    2. 损失记录：跟踪训练和验证损失的变化趋势\n",
    "    3. 学习率调度：支持动态学习率调整\n",
    "    4. 模型检查点：定期保存模型状态\n",
    "    5. 验证评估：定期在验证集上评估模型性能\n",
    "    6. [新增] 混合精度训练：通过 torch.amp 支持 AMP，加速训练并减少显存占用\n",
    "\n",
    "    设计模式：\n",
    "    - 将训练逻辑与模型定义分离，提高代码可维护性\n",
    "    - 支持不同的优化器、损失函数和学习率调度器\n",
    "    - 自动处理GPU/CPU设备切换\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        lr_scheduler,\n",
    "        device,\n",
    "        use_amp: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        初始化训练器\n",
    "\n",
    "        Args:\n",
    "            model: 待训练的神经网络模型\n",
    "            optimizer: 优化器 (如Adam, SGD等)\n",
    "            loss_fn: 损失函数 (如BCEWithLogitsLoss, CrossEntropyLoss等)\n",
    "            lr_scheduler: 学习率调度器 (如ExponentialLR, StepLR等)\n",
    "            device: 训练设备 (例如, torch.device('mps'))\n",
    "            use_amp (bool): 是否启用自动混合精度 (AMP)\n",
    "        \"\"\"\n",
    "        # 训练历史记录\n",
    "        self.validation_losses = []  # 验证集损失历史\n",
    "        self.batch_losses = []  # 所有batch损失历史\n",
    "        self.epoch_losses = []  # 每个epoch平均损失\n",
    "        self.learning_rates = []  # 学习率变化历史\n",
    "\n",
    "        # 训练组件\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.device = device\n",
    "        self.use_amp = use_amp\n",
    "\n",
    "        # 将模型移动到指定设备\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # self.scaler = torch.amp.GradScaler('mps', enabled=self.use_amp)\n",
    "\n",
    "        print(\n",
    "            f\"训练器初始化完成。设备: {self.device}, 自动混合精度(AMP): {'启用' if self.use_amp else '禁用'}\"\n",
    "        )\n",
    "\n",
    "        # 验证优化器和模型的参数是否匹配\n",
    "        self._check_optim_net_aligned()\n",
    "\n",
    "    def _check_optim_net_aligned(self):\n",
    "        \"\"\"\n",
    "        验证优化器是否正确绑定到模型参数\n",
    "        \"\"\"\n",
    "        assert self.optimizer.param_groups[0]['params'] == list(\n",
    "            self.model.parameters()\n",
    "        ), \"优化器参数与模型参数不匹配！\"\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        train_dataloader: DataLoader,\n",
    "        test_dataloader: DataLoader,\n",
    "        epochs: int = 10,\n",
    "        eval_every: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        模型训练主循环\n",
    "        \"\"\"\n",
    "        for e in range(epochs):\n",
    "            print(f\"=== Epoch {e+1}/{epochs} ===\")\n",
    "            print(f\"当前学习率: {self.lr_scheduler.get_last_lr()}\")\n",
    "            self.learning_rates.append(self.lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "            batch_losses, sub_batch_losses = [], []\n",
    "\n",
    "            # ========================\n",
    "            # 训练阶段 (Training Phase)\n",
    "            # ========================\n",
    "            self.model.train()  # 设置模型为训练模式\n",
    "            for i, data in enumerate(train_dataloader):\n",
    "\n",
    "                # (修正) 将进度显示逻辑调整为 (i+1)，避免跳过第0个batch\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    avg_loss = (\n",
    "                        torch.Tensor(sub_batch_losses).mean()\n",
    "                        if sub_batch_losses\n",
    "                        else 0\n",
    "                    )\n",
    "                    print(\n",
    "                        f' 训练 Batch {i+1:4d}/{len(train_dataloader)} | 平均损失: {avg_loss:.6f}'\n",
    "                    )\n",
    "                    sub_batch_losses.clear()\n",
    "\n",
    "                images, mask = data\n",
    "                images = images.to(self.device)\n",
    "                mask = mask.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # === AMP 前向传播 (修改) ===\n",
    "                # autocast 上下文管理器会自动为不同op选择合适的精度(float16或float32)。\n",
    "                # `device_type` 应与你的设备匹配 ('mps', 'cuda', 'cpu')。\n",
    "                # 参考文档: https://pytorch.org/docs/stable/amp.html#autocasting\n",
    "                with torch.autocast(\n",
    "                    device_type='mps',\n",
    "                    dtype=torch.bfloat16,\n",
    "                    enabled=self.use_amp,\n",
    "                ):\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.loss_fn(outputs, mask)\n",
    "\n",
    "                # self.scaler.scale(loss).backward()\n",
    "                # self.scaler.step(self.optimizer)\n",
    "                # self.scaler.update()\n",
    "                \n",
    "                # 后向传播\n",
    "                loss.backward()\n",
    "                # 优化器往后传播梯度并更新参数\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                loss_item = loss.item()\n",
    "                self.batch_losses.append(loss_item)\n",
    "                batch_losses.append(loss_item)\n",
    "                sub_batch_losses.append(loss_item)\n",
    "\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            mean_epoch_loss = torch.Tensor(batch_losses).mean().item()\n",
    "            self.epoch_losses.append(mean_epoch_loss)\n",
    "            print(f'  训练损失: {mean_epoch_loss:.6f}')\n",
    "\n",
    "            # ========================\n",
    "            # 验证阶段 (Validation Phase)\n",
    "            # ========================\n",
    "            if (e + 1) % eval_every == 0:\n",
    "                os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "                checkpoint_path = f\"checkpoints/model_checkpoint_e{e+1}.pt\"\n",
    "                torch.save(self.model.state_dict(), checkpoint_path)\n",
    "                print(f\"  模型已保存: {checkpoint_path}\")\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    self.model.eval()  # 设置模型为评估模式\n",
    "                    validation_losses = []\n",
    "                    for i, data in enumerate(test_dataloader):\n",
    "                        images, mask = data\n",
    "                        images = images.to(self.device)\n",
    "                        mask = mask.to(self.device)\n",
    "\n",
    "                        # === AMP 验证前向传播 (修改) ===\n",
    "                        # 在验证阶段也使用 autocast，以获得性能提升并确保与训练时行为一致。\n",
    "                        with autocast(\n",
    "                            device_type=self.device.type,\n",
    "                            dtype=torch.float16,\n",
    "                            enabled=self.use_amp,\n",
    "                        ):\n",
    "                            output = self.model(images)\n",
    "                            loss = self.loss_fn(output, mask)\n",
    "\n",
    "                        validation_losses.append(loss.item())\n",
    "\n",
    "                    avg_val_loss = torch.Tensor(validation_losses).mean().item()\n",
    "                    self.validation_losses.append(avg_val_loss)\n",
    "                    print(f\"  验证损失: {avg_val_loss:.6f}\")\n",
    "\n",
    "                    if len(self.validation_losses) > 1:\n",
    "                        if (\n",
    "                            self.validation_losses[-1]\n",
    "                            < self.validation_losses[-2]\n",
    "                        ):\n",
    "                            print(\"  ✅ 验证损失下降\")\n",
    "                        else:\n",
    "                            print(\"  ⚠️ 验证损失上升\")\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f57991",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4292c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# 自定义数据集类\n",
    "# ============================\n",
    "\n",
    "class ContrailsAshDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    飞机尾迹检测数据集类 - 继承自PyTorch Dataset基类\n",
    "    \n",
    "    数据集结构：\n",
    "    - 每个样本包含多个时间帧的卫星图像数据\n",
    "    - 输入：24通道假彩色图像序列 (8个时间帧 × 3个RGB通道)\n",
    "    - 输出：像素级二值掩码 (8个时间帧的标注)\n",
    "    \n",
    "    数据预处理流程：\n",
    "    1. 加载多波段卫星图像 (band_11, band_14, band_15)\n",
    "    2. 计算假彩色合成图像\n",
    "    3. 加载人工标注的像素掩码\n",
    "    4. 张量转换和维度调整\n",
    "    5. 数据类型转换 (float32)\n",
    "    \n",
    "    设计考虑：\n",
    "    - 延迟加载：只在需要时才从磁盘读取数据，节省内存\n",
    "    - 灵活的数据变换：支持训练时的数据增强\n",
    "    - 批处理友好：输出格式适合DataLoader批处理\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, parrent_folder: str):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        Args:\n",
    "            parrent_folder (str): 数据文件夹名称，'train' 或 'validation'\n",
    "                                 对应 ROOT_DATA_DIR/train 或 ROOT_DATA_DIR/validation\n",
    "        \n",
    "        数据集组织结构：\n",
    "        ROOT_DATA_DIR/\n",
    "        ├── train/\n",
    "        │   ├── sample_001/\n",
    "        │   │   ├── band_11.npy    # 8.6μm 红外波段数据\n",
    "        │   │   ├── band_14.npy    # 11.2μm 红外波段数据  \n",
    "        │   │   ├── band_15.npy    # 12.4μm 红外波段数据\n",
    "        │   │   └── human_pixel_masks.npy  # 人工标注掩码\n",
    "        │   └── sample_002/\n",
    "        │       └── ...\n",
    "        └── validation/\n",
    "            └── ...\n",
    "        \"\"\"\n",
    "        # 获取数据文件夹路径\n",
    "        data_folder_path = os.path.join(ROOT_DATA_DIR, parrent_folder)\n",
    "        \n",
    "        # 获取所有文件和文件夹\n",
    "        all_items = os.listdir(data_folder_path)\n",
    "        \n",
    "        # 只保留文件夹，过滤掉文件\n",
    "        sample_ids = [\n",
    "            item for item in all_items \n",
    "            if os.path.isdir(os.path.join(data_folder_path, item))\n",
    "        ]\n",
    "        \n",
    "        # 创建DataFrame存储样本索引，便于后续查找和管理\n",
    "        self.df_idx: pd.DataFrame = pd.DataFrame({'idx': sample_ids})\n",
    "        self.parrent_folder: str = parrent_folder\n",
    "        \n",
    "        print(f\"📊 {parrent_folder} 数据集初始化完成:\")\n",
    "        print(f\"   样本数量: {len(sample_ids)}\")\n",
    "        print(f\"   数据路径: {data_folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集大小\n",
    "        \n",
    "        PyTorch Dataset必须实现的方法之一\n",
    "        用于DataLoader确定数据集的总样本数\n",
    "        \"\"\"\n",
    "        return len(self.df_idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        根据索引获取单个样本\n",
    "        \n",
    "        PyTorch Dataset必须实现的方法之一\n",
    "        支持索引访问: dataset[0], dataset[1], ...\n",
    "        \n",
    "        Args:\n",
    "            idx (int): 样本索引，范围 [0, len(dataset)-1]\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (images, mask)\n",
    "                - images: 输入图像张量 (24, 256, 256) \n",
    "                         24通道 = 8个时间帧 × 3个RGB通道\n",
    "                - mask: 标签掩码张量 (8, 256, 256)\n",
    "                       每个时间帧对应一个二值掩码\n",
    "        \n",
    "        数据变换过程：\n",
    "        1. 获取样本ID\n",
    "        2. 加载假彩色图像 (256, 256, 8, 3)\n",
    "        3. 重塑为 (256, 256, 24) - 将时间和通道维度合并\n",
    "        4. 转换为PyTorch张量并调整维度顺序为 (C, H, W)\n",
    "        5. 加载掩码数据并进行相同的张量转换\n",
    "        \"\"\"\n",
    "        # 根据索引获取样本ID\n",
    "        image_id: str = str(self.df_idx.iloc[idx]['idx'])\n",
    "        \n",
    "        # 加载假彩色图像数据\n",
    "        # get_mask_frame_only=False: 加载所有8个时间帧\n",
    "        # 返回形状: (height=256, width=256, time_frames=8, rgb_channels=3)\n",
    "        ash_color_images = get_ash_color_images(\n",
    "            image_id, self.parrent_folder, get_mask_frame_only=False\n",
    "        )\n",
    "        \n",
    "        # 重塑图像数据：将时间帧和RGB通道合并\n",
    "        # (256, 256, 8, 3) -> (256, 256, 24)\n",
    "        # 这样做的原因：\n",
    "        # 1. U-Net期望固定的输入通道数\n",
    "        # 2. 将时序信息编码为多通道特征\n",
    "        # 3. 简化网络结构，避免处理时序维度\n",
    "        reshaped_images = np.reshape(ash_color_images, (256, 256, 24))\n",
    "        \n",
    "        # 转换为PyTorch张量并调整维度\n",
    "        # numpy: (H, W, C) -> torch: (C, H, W)\n",
    "        # 原因：PyTorch卷积层期望通道优先的格式\n",
    "        images = (\n",
    "            torch.tensor(reshaped_images)\n",
    "            .to(torch.float32)           # 确保数据类型为float32\n",
    "            .permute(2, 0, 1)           # (H, W, C) -> (C, H, W)\n",
    "        )\n",
    "        \n",
    "        # 加载标签掩码\n",
    "        mask_data = get_mask_image(image_id, self.parrent_folder)\n",
    "        \n",
    "        # 转换掩码为PyTorch张量\n",
    "        # 形状: (H, W, T) -> (T, H, W) 其中T是时间帧数\n",
    "        mask = (\n",
    "            torch.tensor(mask_data)\n",
    "            .to(torch.float32)           # BCEWithLogitsLoss需要float类型\n",
    "            .permute(2, 0, 1)           # (H, W, T) -> (T, H, W)\n",
    "        )\n",
    "        \n",
    "        return images, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c36fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 优化版数据加载器配置\n",
    "# ============================\n",
    "\n",
    "# 创建训练和验证数据集实例\n",
    "print(\"🔄 正在初始化数据集...\")\n",
    "dataset_train = ContrailsAshDataset('train')\n",
    "dataset_validation = ContrailsAshDataset('validation')\n",
    "\n",
    "# ========================\n",
    "# 数据加载器优化配置\n",
    "# ========================\n",
    "# 配置数据加载器参数\n",
    "BATCH_SIZE = 16        # 稍微增加批大小以提高GPU利用率\n",
    "SHUFFLE_TRAIN = True   # 训练集随机打乱\n",
    "SHUFFLE_VAL = False    # 验证集不打乱以保持一致性\n",
    "\n",
    "print(\"⚙️ 优化版数据加载器配置:\")\n",
    "print(f\"   批大小: {BATCH_SIZE}\")\n",
    "print(f\"   训练集打乱: {SHUFFLE_TRAIN}\")\n",
    "\n",
    "# ========================\n",
    "# 数据加载器性能优化技巧\n",
    "# ========================\n",
    "\n",
    "# 创建训练数据加载器 - 性能优化版\n",
    "data_loader_train = DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE_TRAIN,\n",
    "    # num_workers=NUM_WORKERS,\n",
    "    drop_last=True,                 # 保证batch大小一致\n",
    "    generator=torch.Generator().manual_seed(SEED)  # 确保可重现性\n",
    ")\n",
    "\n",
    "# 创建验证数据加载器 - 性能优化版\n",
    "data_loader_validation = DataLoader(\n",
    "    dataset_validation, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE_VAL,\n",
    "    # num_workers=NUM_WORKERS,\n",
    "    drop_last=False,                # 验证时保留所有数据\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(\"✅ 优化版数据加载器创建完成!\")\n",
    "print(f\"   训练批次数: {len(data_loader_train)}\")\n",
    "print(f\"   验证批次数: {len(data_loader_validation)}\")\n",
    "print(f\"   每epoch训练样本: {len(data_loader_train) * BATCH_SIZE}\")\n",
    "print(f\"   每epoch验证样本: {len(dataset_validation)}\")\n",
    "\n",
    "# ========================\n",
    "# 数据加载器优化说明\n",
    "# ========================\n",
    "print(\"\\n💡 已应用的数据加载优化:\")\n",
    "print(\"✅ 批大小优化: 平衡内存使用和GPU利用率\")\n",
    "print(\"✅ 可重现性: 固定随机种子确保结果一致\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fca0f3",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cdbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 模型训练配置与执行 - 包含训练加速优化\n",
    "# ============================\n",
    "\n",
    "# 训练控制开关\n",
    "train = True  # True: 从头训练新模型, False: 加载预训练模型\n",
    "\n",
    "if train:\n",
    "    print(\"🚀 开始训练新模型...\")\n",
    "\n",
    "    # ========================\n",
    "    # 训练加速优化设置\n",
    "    # ========================\n",
    "    # 1. 启用编译模式加速 (PyTorch 2.0+)\n",
    "    torch.backends.cudnn.benchmark = True  # 对固定输入大小启用cuDNN优化\n",
    "\n",
    "    print(\"✅ 训练加速优化已启用\")\n",
    "    print(\"   - cuDNN benchmark: True\")\n",
    "\n",
    "    # ========================\n",
    "    # 模型初始化\n",
    "    # ========================\n",
    "    model = UNet() \n",
    "    model.to(mps_device)  # 将模型移动到MPS设备\n",
    "    print(f\"✅ 模型已加载到设备: {mps_device}\")\n",
    "\n",
    "    # ========================\n",
    "    # 损失函数配置 - 内存优化版本\n",
    "    # ========================\n",
    "    # 使用带权重的二元交叉熵损失 (Binary Cross Entropy with Logits Loss)\n",
    "    # 将pos_weight移动到设备上，避免每次forward时的数据传输\n",
    "    pos_weight = torch.tensor(100.0, device=mps_device, dtype=torch.float32)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    print(\"📊 损失函数: BCEWithLogitsLoss (pos_weight=100, 设备优化)\")\n",
    "\n",
    "    # ========================\n",
    "    # 优化器配置 - 性能调优版本\n",
    "    # ========================\n",
    "    # Adam优化器配置，添加性能优化参数\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.01,\n",
    "        weight_decay=1e-5,  # 添加轻微L2正则化，有助于收敛\n",
    "    )\n",
    "    print(\"🎯 优化器: Adam (性能优化版本)\")\n",
    "\n",
    "    # ========================\n",
    "    # 学习率调度器 -\n",
    "    # ========================\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.70)\n",
    "\n",
    "    # ========================\n",
    "    # 训练超参数\n",
    "    # ========================\n",
    "    num_epochs = 11  # 训练轮次\n",
    "\n",
    "    # ========================\n",
    "    # 训练执行 - 增强版训练器\n",
    "    # ========================\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🚀 开始优化训练过程...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    trainer = MyTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=criterion,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        device=mps_device,\n",
    "        use_amp=True,  # 设置为 True 以启用混合精度\n",
    "    )\n",
    "\n",
    "    # 执行优化训练\n",
    "    trainer.fit(\n",
    "        train_dataloader=data_loader_train,\n",
    "        test_dataloader=data_loader_validation,\n",
    "        epochs=num_epochs,\n",
    "        eval_every=1,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎉 优化训练完成！\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "else:\n",
    "    # ========================\n",
    "    # 加载预训练模型\n",
    "    # ========================\n",
    "    print(\"📂 加载预训练模型...\")\n",
    "    model = UNet()\n",
    "\n",
    "    model_path = 'checkpoints/model_checkpoint_e11.pt'  # 更新路径\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "        print(f\"✅ 成功加载模型: {model_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 模型文件未找到: {model_path}\")\n",
    "        print(\"请检查文件路径或先运行训练代码\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 模型加载失败: {e}\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(mps_device)\n",
    "    print(f\"🔍 模型已设置为评估模式并移动到: {mps_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1357309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if train:\n",
    "    df_data = pd.DataFrame({'Batch Losses': trainer.batch_losses})\n",
    "    sns.lineplot(data=df_data)\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Batch Loss')\n",
    "    plt.show()\n",
    "\n",
    "    df_data = pd.DataFrame({'Batch Losses': trainer.epoch_losses})\n",
    "    sns.lineplot(data=df_data)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Epoch Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f65cca",
   "metadata": {},
   "source": [
    "# FIND OPTIMAL THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdf7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class DiceThresholdTester:\n",
    "\n",
    "    def __init__(\n",
    "        self, model: nn.Module, data_loader: torch.utils.data.DataLoader\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.cumulative_mask_pred = []\n",
    "        self.cumulative_mask_true = []\n",
    "\n",
    "    def precalculate_prediction(self) -> None:\n",
    "        sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for images, mask_true in self.data_loader:\n",
    "            if mps_device:\n",
    "                images = images.to(mps_device)\n",
    "\n",
    "            mask_pred = sigmoid(model.forward(images))\n",
    "\n",
    "            self.cumulative_mask_pred.append(mask_pred.cpu().detach().numpy())\n",
    "            self.cumulative_mask_true.append(mask_true.cpu().detach().numpy())\n",
    "\n",
    "        self.cumulative_mask_pred = np.concatenate(\n",
    "            self.cumulative_mask_pred, axis=0\n",
    "        )\n",
    "        self.cumulative_mask_true = np.concatenate(\n",
    "            self.cumulative_mask_true, axis=0\n",
    "        )\n",
    "\n",
    "        self.cumulative_mask_pred = torch.flatten(\n",
    "            torch.from_numpy(self.cumulative_mask_pred)\n",
    "        )\n",
    "        self.cumulative_mask_true = torch.flatten(\n",
    "            torch.from_numpy(self.cumulative_mask_true)\n",
    "        )\n",
    "\n",
    "    def test_threshold(self, threshold: float) -> float:\n",
    "        _dice = Dice(use_sigmoid=False)\n",
    "        after_threshold = np.zeros(self.cumulative_mask_pred.shape)\n",
    "        after_threshold[self.cumulative_mask_pred[:] > threshold] = 1\n",
    "        after_threshold[self.cumulative_mask_pred[:] < threshold] = 0\n",
    "        after_threshold = torch.flatten(torch.from_numpy(after_threshold))\n",
    "        return _dice(self.cumulative_mask_true, after_threshold).item()\n",
    "\n",
    "# ============================\n",
    "dice_threshold_tester = DiceThresholdTester(model, data_loader_validation)\n",
    "dice_threshold_tester.precalculate_prediction()\n",
    "\n",
    "thresholds_to_test = [round(x * 0.01, 2) for x in range(101)]\n",
    "\n",
    "optim_threshold = 0.975\n",
    "best_dice_score = -1\n",
    "\n",
    "thresholds = []\n",
    "dice_scores = []\n",
    "\n",
    "for t in tqdm(thresholds_to_test, desc=\"Testing thresholds\"):\n",
    "    dice_score = dice_threshold_tester.test_threshold(t)\n",
    "    if dice_score > best_dice_score:\n",
    "        best_dice_score = dice_score\n",
    "        optim_threshold = t\n",
    "\n",
    "    thresholds.append(t)\n",
    "    dice_scores.append(dice_score)\n",
    "\n",
    "print(f'Best Threshold: {optim_threshold} with dice: {best_dice_score}')\n",
    "df_threshold_data = pd.DataFrame(\n",
    "    {'Threshold': thresholds, 'Dice Score': dice_scores}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_threshold_data, x='Threshold', y='Dice Score')\n",
    "plt.axhline(y=best_dice_score, color='green')\n",
    "plt.axvline(x=optim_threshold, color='green')\n",
    "plt.text(\n",
    "    -0.02,\n",
    "    best_dice_score * 0.96,\n",
    "    f'{best_dice_score:.3f}',\n",
    "    va='center',\n",
    "    ha='left',\n",
    "    color='green',\n",
    ")\n",
    "plt.text(\n",
    "    optim_threshold - 0.01,\n",
    "    0.02,\n",
    "    f'{optim_threshold}',\n",
    "    va='center',\n",
    "    ha='right',\n",
    "    color='green',\n",
    ")\n",
    "plt.ylim(bottom=0)\n",
    "plt.title('Threshold vs Dice Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786abc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
